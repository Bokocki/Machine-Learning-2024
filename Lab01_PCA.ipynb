{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SzymonNowakowski/Machine-Learning-2024/blob/master/Lab01_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68688b1a",
      "metadata": {
        "id": "68688b1a"
      },
      "source": [
        "# Lab1 - PCA\n",
        "### Author: Szymon Nowakowski\n",
        "\n",
        "In this lab, we will perform *exploratory data analysis* (EDA) with a focus on understanding complex data through Principal Component Analysis (PCA).\n",
        "\n",
        "# Motivation\n",
        "\n",
        "Let's assume $X$ is an $n \\times k$ **data** matrix. Let's further assume it is **centered**:\n",
        "\n",
        "$$\n",
        "X =\n",
        "\\begin{bmatrix}\n",
        "x_{11} & x_{12} & \\dots & x_{1k} \\\\\n",
        "x_{21} & x_{22} & \\dots & x_{2k} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "x_{n1} & x_{n2} & \\dots & x_{nk}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "## Inner Product as Projection Length\n",
        "\n",
        "When we take the inner product of a vector $x$ with normalized $w$, we’re effectively measuring its \"shadow\" or \"projection\" onto\n",
        "$w$. The inner product is a scalar value. This scalar represents the length of\n",
        "$x$ along the direction of\n",
        "$w$—essentially, how far\n",
        "$x$ extends in the\n",
        "$w$ direction. So, the inner product\n",
        "$x \\cdot w$ gives the projection length.\n",
        "\n",
        "![inner product is a projection length](https://github.com/SzymonNowakowski/Machine-Learning-2024/blob/master/inner_product_as_projection_length.png?raw=1)\n",
        "\n",
        "The product\n",
        "$X w$ generalizes this concept, projecting all rows (all data points) of\n",
        "$X$ onto the line defined by\n",
        "$w$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "To calculate the sample covariance matrix $C$ from this centered matrix $X$, we use the formula:\n",
        "\n",
        "$$\n",
        "C = \\frac{1}{n - 1} X^T X\n",
        "$$\n",
        "\n",
        "$C$ is the $ k \\times k $ sample covariance matrix. Since $C$ is symmetric, it can be decomposed as $C = V \\Lambda V^T$, where\n",
        "- $V$ is an orthonormal $ k \\times k $ matrix and\n",
        "- $\\Lambda$ is a diagonal $ k \\times k $ matrix containing the eigenvalues of $C$.\n",
        "\n",
        "Because $V$ is orthonormal, we have $V^T V = I_k$, where $I_k$ is the identity matrix.\n",
        "\n",
        "Our goal is finding such a $w$, that the projection's $X w$ variance is maximized:\n",
        "\n",
        "$$\n",
        "\\text{Var}(X w) \\longrightarrow \\max_{\\|w\\| = 1}\n",
        "$$\n",
        "\n",
        "Obviously we restrict $w$ to normalized vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55cfb727",
      "metadata": {
        "id": "55cfb727"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Importing necessary libraries for data manipulation, visualization, and PCA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Setting visualization style\n",
        "sns.set(style=\"whitegrid\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}